原文链接:[分词和分词器](https://www.elastic.co/guide/en/elasticsearch/guide/current/analysis-intro.html)
### 分词和分词器
分词是由下面的两个过程组成的:
+ 首先，把一块文本解析成独立的词条，在倒排索引中会用到词条。
+ 然后，把第一步解析后的词条做标准化处理，标准化处理可以提高可搜索性或者回查率。

分词的工作是由分词器来做的。分词器其实是一个包装器，分词器把三个功能组合成一个独立的包装:

#### 字符过滤器（可以有多个）
首先，字符串会按顺序传递给所有的字符过滤器。字符串过滤是为了在解析 token 之前清理字符串。一个字符过滤器可以用来剥离 html ，或者把 & 字符转换为单词 and 。

#### token 解析器（只有一个）
然后，字符串被字符串解析器解析成独立的词条。一个简单的 token 解析器可能只要它遇到空格或者标点符号就解析成一个词条。

### token 过滤器（可以有多个）
最后，会把每个词条都传递给所有的 token 过滤器，token 过滤器可以改变词条（例如，小写化 Quick），删除词条（例如，停用词，比如 a、an、the） 或者添加词条（比如，同义词，比如 jump 和 leap）。

es 提供了好多字符过滤器，token 解析器和 token 过滤器，可以开箱即用。这些内置的功能可以在自定义分词器的时候组合使用来满足自己的需求。我们在自定义分词中会讨论详情。

